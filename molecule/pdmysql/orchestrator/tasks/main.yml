---
# tasks file for pdps
  - name: include playbook for removing Percona repo
    include: ../../../tasks/remove_percona_repository.yml

  - name: Install percona release
    include: ../../tasks/install_percona_release.yml

  - name: clean and update yum cache
    shell: |
      yum clean all
      yum makecache
    when: ansible_os_family == "RedHat"

  - name: disable the mysql module on RHEL/CentOS 8
    command: yum module disable mysql -y
    when: ansible_os_family == "RedHat" and ansible_distribution_major_version >= "8"

  - name: disable the mariadb module on RHEL/CentOS 8
    command: yum module disable mariadb -y
    when: ansible_os_family == "RedHat" and ansible_distribution_major_version >= "8"

  - name: enable the PDMYSQL-80 repo
    command: percona-release enable-only pdps-{{ version }} {{ repo }}
    vars:
      repo: "{{ lookup('env', 'REPO') }}"
      version: "{{ lookup('env', 'VERSION') }}"


  - name: install Percona Toolkit
    include_tasks: ../../../tasks/install_pt.yml

  - name: clean yum
    shell: |
      yum clean all
      yum makecache
    when: ansible_os_family == "RedHat"

  - name: install Percona Server deb packages
    apt:
      name: "{{ packages }}"
      update_cache: yes
      state: latest
    vars:
      packages:
      - percona-server-server
      - percona-server-test
      - percona-server-dbg
      - percona-server-source
      - percona-server-client
      - percona-server-tokudb
      - percona-server-rocksdb
    when: ansible_os_family == "Debian"

  - name: install Percona XtraBackup 8.0 packages
    include_tasks: ../../../tasks/install_pxb80.yml

  - name: install proxysql new deb packages
    apt:
      name: "{{ packages }}"
      update_cache: yes
      state: latest
    vars:
      packages:
        - proxysql2
    when: ansible_os_family == "Debian"

  - name: start proxysql service
    service: name=proxysql state=started

  - name: stop proxysql service
    service: name=proxysql state=stopped

  - name: start proxysql service
    service: name=proxysql state=started

  - name: install orchestrator new deb packages
    apt:
      name: "{{ packages }}"
      update_cache: yes
      state: latest
    vars:
      packages:
        - percona-orchestrator-cli
        - percona-orchestrator-client
        - percona-orchestrator
    when: ansible_os_family == "Debian"

  - name: install percona-mysql-shell package for Debian/Ubuntu
    apt:
      update_cache: yes
      state: present
      name: "{{ packages }}"
    vars:
      packages:
      - percona-mysql-shell
    when: ansible_os_family == "Debian"

  - name: install percona-mysql-router package for Debian/Ubuntu
    apt:
      update_cache: yes
      state: present
      name: "{{ packages }}"
    vars:
      packages:
      - percona-mysql-router
    when: ansible_os_family == "Debian"

  - name: download golang tar
    get_url:
      url: "https://golang.org/dl/go1.16.5.linux-amd64.tar.gz"
      dest: "/tmp"
      mode: 0440
    when: ansible_os_family == "Debian"

  - name: Remove old installation of Go
    file:
      path: /usr/local/go
      state: absent
    become: yes
    when: ansible_os_family == "Debian"

  - name: Extract the Go tarball
    unarchive:
      src: "/tmp/go1.16.5.linux-amd64.tar.gz"
      dest: /usr/local
      copy: no
    become: yes
    when: ansible_os_family == "Debian"

  - name: Clone orchestrator sources
    git:
      repo: https://github.com/openark/orchestrator.git
      version: v3.2.4
      dest: /root/orchestrator

  - name: Clone orchestrator-ci-env sources
    git:
      repo: https://github.com/openark/orchestrator-ci-env.git
      version: master
      dest: /root/orchestrator-ci-env

  - name: Install haproxy for orchestrator system test debian
    apt:
      update_cache: yes
      state: present
      name: "{{ packages }}"
    vars:
      packages:
      - haproxy
    when: ansible_os_family == "Debian"

  - name: start haproxy service
    service: name=haproxy state=started

  - name: Unarchive a consul
    unarchive:
      src: /root/orchestrator-ci-env/bin/consul.gz
      dest: /usr/local/bin
      remote_src: yes

  - name: Unarchive a consul-template
    unarchive:
      src: /root/orchestrator-ci-env/bin/consul-template.gz
      dest: /usr/local/bin
      remote_src: yes

  - name: Deploy consul
    script:
      cmd: script/deploy-consul
      chdir: /root/orchestrator-ci-env

  - name: Run consul
    script:
      cmd: script/run-consul
      chdir: /root/orchestrator-ci-env

  - name: Test consul
    shell: sudo systemctl status consul
    register: consul_status

  - name: Print test consul service status
    debug:
      var: consul_status
      verbosity: 2

  - name: Deploy consul-template
    script:
      cmd: script/deploy-consul-template
      chdir: /root/orchestrator-ci-env

  - name: test consul template binary
    shell: /usr/local/bin/consul-template --version

  - name: Run consul-template
    script:
      cmd: script/run-consul-template || (sudo journalctl -u consul-template.service ; exit 1)
      chdir: /root/orchestrator-ci-env

  - name: Test consul-template service
    shell: sudo systemctl status consul-template || (sudo journalctl -u consul-template.service ; exit 1)
    register: consul_template_status

  - name: Populate consul kv
    shell: consul kv put "mysql/master/ci/hostname" "127.0.0.1"

  - name: Populate consul  port
    shell: consul kv put "mysql/master/ci/port" "10111"

  - name: Test consul kv
    shell: consul kv get "mysql/master/ci/port" | grep -q 10111
    register: consul_test

  - name: Print test consul kv test
    debug:
      var: consul_test
      verbosity: 2

  - name: Test consul kv API
    shell: curl -s http://127.0.0.1:8500/v1/kv/mysql/master/ci/port | jq -r '.[].Value' | base64 --decode | grep -q 10111
    register: consul_api_test

  - name: test consul-template template
    shell: grep 10111 /etc/haproxy/haproxy.cfg || (sudo journalctl -u consul-template.service ; exit 1)

# Create replica

  - name: Create test directories for orchestrator system test
    file:
      path: "{{ item }}"
      state: directory
      owner: root
      group: root
      recurse: yes
    with_items:
      - /root/sandboxes/ci/master/data
      - /root/sandboxes/ci/master/tmp
      - /root/sandboxes/ci/node1/data
      - /root/sandboxes/ci/node1/tmp
      - /root/sandboxes/ci/node2/data
      - /root/sandboxes/ci/node2/tmp
      - /root/sandboxes/ci/node3/data
      - /root/sandboxes/ci/node3/tmp

  - name: Copy config files to sandboxes
    template:
      src: "my.sandbox.cn_{{ item }}"
      dest: "/root/sandboxes/ci/{{ item }}/my.sandbox.cnf"
      lstrip_blocks: yes
      owner: root
      group: root
      mode: 0644
    with_items:
      - master
      - node1
      - node2
      - node3

  - name: Initialize data directory
    shell: "mysqld --no-defaults  --user=root --basedir=/usr/bin --datadir={{ item }}/data --tmpdir=/root/sandboxes/ci/{{ item }}/tmp --initialize-insecure"
    with_items:
      - /root/sandboxes/ci/master/
      - /root/sandboxes/ci/node1/
      - /root/sandboxes/ci/node2/
      - /root/sandboxes/ci/node3/

  - name: Start mysql
    shell: "mysqld_safe --defaults-file={{ item }}/my.sandbox.cnf &"
    with_items:
      - /root/sandboxes/ci/master/
      - /root/sandboxes/ci/node1/
      - /root/sandboxes/ci/node2/
      - /root/sandboxes/ci/node3/

  - name: Create CI user
    mysql_query:
      query: CREATE USER 'ci'@'localhost' IDENTIFIED BY 'ci';
      login_user: root
      login_port: 10111

  - name: Grant CI user
    mysql_query:
      query: GRANT ALL ON *.* TO 'ci'@'localhost';
      login_user: root
      login_port: 10111

  - name: Create heartbeat user
    mysql_query:
      query: CREATE USER 'heartbeat'@'localhost' IDENTIFIED BY 'heartbeat';
      login_user: root
      login_port: 10111

  - name: Grant heartbeat user
    mysql_query:
      query: GRANT ALL ON test.* TO 'heartbeat'@'localhost';
      login_user: root
      login_port: 10111

  - name: Set master global read_only
    mysql_query:
      query: set global read_only=0;
      login_user: root
      login_port: 10111

  - name: Create test DB
    mysql_query:
      query: CREATTE DATABASE test;
      login_user: root
      login_port: 10111

  - name: Configure slaves
    mysql_replication:
      mode: changemaster
      login_user: root
      login_port: "{{ item }}"
      primary_host: localhost
      primary_port: 10111
      primary_user: ci
      primary_password: ci
      primary_ssl: no
      master_connect_retry: 1
      master_auto_position: no
    with_items:
      - 10112
      - 10113
      - 10114

  - name: Start slaves
    mysql_replication:
      mode: startslave
      login_user: root
      login_port: "{{ item }}"
    with_items:
      - 10112
      - 10113
      - 10114

  - name: Get master
    mysql_replication:
      mode: getmaster
      login_user: root
      login_port: 10111
    register: slave1_status

  - name: Get slave1
    mysql_replication:
      mode: getslave
      login_user: root
      login_port: 10112
    register: slave1_status

  - name: Get slave2
    mysql_replication:
      mode: getslave
      login_user: root
      login_port: 10113
    register: slave2_status

  - name: Get slave3
    mysql_replication:
      mode: getslave
      login_user: root
      login_port: 10114
    register: slave3_status

  - name: test mysql master
    shell: mysql -uci -pci -h 127.0.0.1 --port 10111 -s -s -e "select @@report_port" | grep -q 10111

  - name: test read_only
    shell: |
      ro="$(mysql -uci -pci -h 127.0.0.1 --port 10111 -s -s -e "select @@global.read_only")"
      if [ "$ro" != "0" ] ; then
        echo "expected read_only=0 on master, got $ro"
        exit 1
      fi
      ro="$(mysql -uci -pci -h 127.0.0.1 --port 10112 -s -s -e "select @@global.read_only")"
      if [ "$ro" != "1" ] ; then
        echo "expected read_only=1 on replica, got $ro"
        exit 1
      fi
      echo "read_only" validated

  - name: test haproxy routing to mysql master
    shell: mysql -uci -pci -h 127.0.0.1 --port 13306 -s -s -e "select @@report_port" | grep -q 10111

  - name: Deploy mysql heartbeat
    script:
      cmd: script/deploy-heartbeat
      chdir: /root/orchestrator-ci-env

  - name: Start mysql heartbeat service
    script: script/run-heartbeat || (sudo journalctl -u mysql-heartbeat.service ; exit 1)

  - name: Check heartbeat
    shell: |
      sleep 1
      ts1="$(mysql -uci -pci -h 127.0.0.1 --port 13306 -s -s -e "select ts from test.heartbeat")"
      sleep 1
      ts2="$(mysql -uci -pci -h 127.0.0.1 --port 13306 -s -s -e "select ts from test.heartbeat")"
      if [ "$ts1" == "$ts2" ] ; then
        echo "heartbeat test fail: '$ts1'=='$ts2'"
        exit 1
      fi
      echo "heartbeat test success: '$ts1'!='$ts2'"
    register: hb_ts1

  - name: Copy orchestrator service file
    shell:
      cmd: sudo cp etc/systemd/orchestrator.service /etc/systemd/system/
      chdir: /root/orchestrator-ci-env

  - name: Create orchestrator local directory
    shell:
      cmd: sudo mkdir -p /usr/local/orchestrator

  - name: Copy orchestrator binary
    shell:
      cmd: sudo cp /usr/bin/orchestrator /usr/local/orchestrator/

  - name: Copy orchestrator configuration file
    shell:
      cmd: sudo cp tests/system/orchestrator-ci-system.conf.json /etc/orchestrator.conf.json
      chdir: /root/orchestrator-ci-env

  - name: reload systemctl
    service:
      daemon_reload: yes
      name: orchestrator
      state: started

  - name: Get orchestrator-client status
    shell: orchestrator-client -c api -path status | jq .
    register: orchestrator_client_status

  - name: Print orchestrator-client status
    debug:
      var: orchestrator_client_status
      verbosity: 2

  - name: graceful sleep
    pause:
      seconds: 20

  - name: Get clusters-alias status
    shell: orchestrator-client -c clusters-alias
    register: orchestrator_cluser_alias

  - name: Print clusters-alias status
    debug:
      var: orchestrator_cluser_alias
      verbosity: 2

  - name: Get orchestrator all instances
    shell: orchestrator-client -c all-instances
    register: orchestrator_all_instances

  - name: Print clusters-alias status
    debug:
      var: orchestrator_all_instances
      verbosity: 2

  - name: Get replication-analysis
    shell: orchestrator-client -c replication-analysis
    register: orchestrator_replication_analysis

  - name: Print replication-analysis status
    debug:
      var: orchestrator_replication_analysis
      verbosity: 2

  - name: Get orchestrator_topology_tabulated
    shell: orchestrator-client -c topology-tabulated -alias ci
    register: orchestrator_topology_tabulated

  - name: Print orchestrator_topology_tabulated status
    debug:
      var: orchestrator_topology_tabulated
      verbosity: 2
  - name: Get consul KV values
    shell: consul kv get -recurse mysql/master
    register: consul_kv_values

  - name: Print clusters-alias status
    debug:
      var: consul_kv_values
      verbosity: 2
